1.

2. Не могут, т.к. у них одинаковый inode (т.е. это один и тот же объект в файловой системе).

3.

4.

        vagrant@vagrant:~$ sudo -i
        # Находим интересующие нас диски по 2.5 ГБ:
        root@vagrant:~# fdisk -l
        ...
        Disk /dev/sdb: 2.51 GiB, 2684354560 bytes, 5242880 sectors
        Disk model: VBOX HARDDISK
        Units: sectors of 1 * 512 = 512 bytes
        Sector size (logical/physical): 512 bytes / 512 bytes
        I/O size (minimum/optimal): 512 bytes / 512 bytes
        
        Disk /dev/sdc: 2.51 GiB, 2684354560 bytes, 5242880 sectors
        Disk model: VBOX HARDDISK
        Units: sectors of 1 * 512 = 512 bytes
        Sector size (logical/physical): 512 bytes / 512 bytes
        I/O size (minimum/optimal): 512 bytes / 512 bytes
        ...
        
        root@vagrant:~# fdisk /dev/sdb
        Command (m for help): n
        Partition type
           p   primary (0 primary, 0 extended, 4 free)
           e   extended (container for logical partitions)
        Select (default p):
        
        Using default response p.
        Partition number (1-4, default 1):
        First sector (2048-5242879, default 2048):
        Last sector, +/-sectors or +/-size{K,M,G,T,P} (2048-5242879, default 5242879): +2G
        
        Created a new partition 1 of type 'Linux' and of size 2 GiB.
        
        Command (m for help): n
        Partition type
           p   primary (1 primary, 0 extended, 3 free)
           e   extended (container for logical partitions)
        Select (default p):
        
        Using default response p.
        Partition number (2-4, default 2):
        First sector (4196352-5242879, default 4196352):
        Last sector, +/-sectors or +/-size{K,M,G,T,P} (4196352-5242879, default 5242879):
        
        Created a new partition 2 of type 'Linux' and of size 511 MiB.
        
        Command (m for help): w
        The partition table has been altered.
        Calling ioctl() to re-read partition table.
        Syncing disks.
        
        root@vagrant:~# fdisk -l /dev/sdb
        Disk /dev/sdb: 2.51 GiB, 2684354560 bytes, 5242880 sectors
        Disk model: VBOX HARDDISK
        Units: sectors of 1 * 512 = 512 bytes
        Sector size (logical/physical): 512 bytes / 512 bytes
        I/O size (minimum/optimal): 512 bytes / 512 bytes
        Disklabel type: dos
        Disk identifier: 0xdd530c17
        
        Device     Boot   Start     End Sectors  Size Id Type
        /dev/sdb1          2048 4196351 4194304    2G 83 Linux
        /dev/sdb2       4196352 5242879 1046528  511M 83 Linux
        root@vagrant:~#

5.

        root@vagrant:~# sfdisk -d /dev/sdb | sfdisk /dev/sdc
        root@vagrant:~# fdisk -l /dev/sdc
        Disk /dev/sdc: 2.51 GiB, 2684354560 bytes, 5242880 sectors
        Disk model: VBOX HARDDISK
        Units: sectors of 1 * 512 = 512 bytes
        Sector size (logical/physical): 512 bytes / 512 bytes
        I/O size (minimum/optimal): 512 bytes / 512 bytes
        Disklabel type: dos
        Disk identifier: 0xdd530c17
        
        Device     Boot   Start     End Sectors  Size Id Type
        /dev/sdc1          2048 4196351 4194304    2G 83 Linux
        /dev/sdc2       4196352 5242879 1046528  511M 83 Linux

6. 

        root@vagrant:~# mdadm --create --verbose /dev/md0 --level=1 --raid-devices=2 /dev/sdb1 /dev/sdc1
        ...
        Continue creating array? y
        mdadm: Defaulting to version 1.2 metadata
        mdadm: array /dev/md0 started.

7. 

        root@vagrant:~# mdadm --create --verbose /dev/md1 --level=0 --raid-devices=2 /dev/sdb2 /dev/sdc2
        mdadm: chunk size defaults to 512K
        mdadm: Defaulting to version 1.2 metadata
        mdadm: array /dev/md1 started.
        
        root@vagrant:~# cat /proc/mdstat
        Personalities : [linear] [multipath] [raid0] [raid1] [raid6] [raid5] [raid4] [raid10]
        md1 : active raid0 sdc2[1] sdb2[0]
              1042432 blocks super 1.2 512k chunks
        
        md0 : active raid1 sdc1[1] sdb1[0]
              2094080 blocks super 1.2 [2/2] [UU]

8.

        root@vagrant:~# pvcreate /dev/md0 /dev/md1
          Physical volume "/dev/md0" successfully created.
          Physical volume "/dev/md1" successfully created.

9.

        root@vagrant:~# vgcreate vgraids /dev/md0 /dev/md1
          Volume group "vgraids" successfully created
  
10.

        root@vagrant:~# lvcreate -L 100M vgraids -n lvraid0 /dev/md1
          Logical volume "lvraid0" created.

11.

        root@vagrant:~# mkfs.ext4 /dev/vgraids/lvraid0
        mke2fs 1.45.5 (07-Jan-2020)
        Creating filesystem with 25600 4k blocks and 25600 inodes
        
        Allocating group tables: done
        Writing inode tables: done
        Creating journal (1024 blocks): done
        Writing superblocks and filesystem accounting information: done

12. 

        root@vagrant:/mnt# mkdir /mnt/test
        root@vagrant:/mnt# mount /dev/vgraids/lvraid0 /mnt/test
        
        root@vagrant:/mnt# df -hT | egrep '(Used|vgraids)'
        Filesystem                  Type      Size  Used Avail Use% Mounted on
        /dev/mapper/vgraids-lvraid0 ext4       93M   72K   86M   1% /mnt/test

13.

        root@vagrant:/mnt# wget https://mirror.yandex.ru/ubuntu/ls-lR.gz -O /mnt/test/test.gz

14.

        root@vagrant:/mnt# lsblk
        NAME                  MAJ:MIN RM  SIZE RO TYPE  MOUNTPOINT
        sda                     8:0    0   64G  0 disk
        ├─sda1                  8:1    0  512M  0 part  /boot/efi
        ├─sda2                  8:2    0    1K  0 part
        └─sda5                  8:5    0 63.5G  0 part
          ├─vgvagrant-root    253:0    0 62.6G  0 lvm   /
          └─vgvagrant-swap_1  253:1    0  980M  0 lvm   [SWAP]
        sdb                     8:16   0  2.5G  0 disk
        ├─sdb1                  8:17   0    2G  0 part
        │ └─md0                 9:0    0    2G  0 raid1
        └─sdb2                  8:18   0  511M  0 part
          └─md1                 9:1    0 1018M  0 raid0
            └─vgraids-lvraid0 253:2    0  100M  0 lvm   /mnt/test
        sdc                     8:32   0  2.5G  0 disk
        ├─sdc1                  8:33   0    2G  0 part
        │ └─md0                 9:0    0    2G  0 raid1
        └─sdc2                  8:34   0  511M  0 part
          └─md1                 9:1    0 1018M  0 raid0
            └─vgraids-lvraid0 253:2    0  100M  0 lvm   /mnt/test

15.

        root@vagrant:/mnt# gzip -t /mnt/test/test.gz
        root@vagrant:/mnt# echo $?
        0

16.

        root@vagrant:/mnt# pvmove /dev/md1 /dev/md0
          /dev/md1: Moved: 8.00%
          /dev/md1: Moved: 100.00%
        root@vagrant:/mnt# lsblk
        NAME                  MAJ:MIN RM  SIZE RO TYPE  MOUNTPOINT
        sda                     8:0    0   64G  0 disk
        ├─sda1                  8:1    0  512M  0 part  /boot/efi
        ├─sda2                  8:2    0    1K  0 part
        └─sda5                  8:5    0 63.5G  0 part
          ├─vgvagrant-root    253:0    0 62.6G  0 lvm   /
          └─vgvagrant-swap_1  253:1    0  980M  0 lvm   [SWAP]
        sdb                     8:16   0  2.5G  0 disk
        ├─sdb1                  8:17   0    2G  0 part
        │ └─md0                 9:0    0    2G  0 raid1
        │   └─vgraids-lvraid0 253:2    0  100M  0 lvm   /mnt/test
        └─sdb2                  8:18   0  511M  0 part
          └─md1                 9:1    0 1018M  0 raid0
        sdc                     8:32   0  2.5G  0 disk
        ├─sdc1                  8:33   0    2G  0 part
        │ └─md0                 9:0    0    2G  0 raid1
        │   └─vgraids-lvraid0 253:2    0  100M  0 lvm   /mnt/test
        └─sdc2                  8:34   0  511M  0 part
          └─md1                 9:1    0 1018M  0 raid0

17.

        root@vagrant:/mnt# mdadm --fail /dev/md0 /dev/sdc1
        mdadm: set /dev/sdc1 faulty in /dev/md0
        
        root@vagrant:/mnt# cat /proc/mdstat
        Personalities : [linear] [multipath] [raid0] [raid1] [raid6] [raid5] [raid4] [raid10]
        md1 : active raid0 sdc2[1] sdb2[0]
              1042432 blocks super 1.2 512k chunks
        
        md0 : active raid1 sdc1[1](F) sdb1[0]
              2094080 blocks super 1.2 [2/1] [U_]

18.

        root@vagrant:/mnt# dmesg -T | tail -n2
        [Wed Jul  7 18:29:17 2021] md/raid1:md0: Disk failure on sdc1, disabling device.
                                   md/raid1:md0: Operation continuing on 1 devices.

19.

        root@vagrant:/mnt# gzip -t /mnt/test/test.gz
        root@vagrant:/mnt# echo $?
        0

